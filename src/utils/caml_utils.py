"""
    CAML utils (Mullenbach et al. 2018)
    https://github.com/jamesmullenbach/caml-mimic
"""
import csv
from collections import defaultdict

import numpy as np
import torch.nn as nn

# From constant.py
PAD_CHAR = "**PAD**"
EMBEDDING_SIZE = 100
MAX_LENGTH = 2500
# Definitions of the below are a bit different from the original CAML
MIMIC_2_DIR = "datasets/mimicdata/mimic2"  # MIMIC-II csv files
MIMIC_3_DIR = "datasets/mimicdata/mimic3"  # MIMIC-III csv files
DATA_DIR = "datasets/mimicdata"  # CAML static & preprocessed data


# From datasets.py
def load_vocab_dict(vocab_file):
    # reads vocab_file into two lookups (word:ind) and (ind:word)
    vocab = set()
    with open(vocab_file, "r") as vocabfile:
        for i, line in enumerate(vocabfile):
            line = line.rstrip()
            if line != "":
                vocab.add(line.strip())
    ind2w = {i + 1: w for i, w in enumerate(sorted(vocab))}
    w2ind = {w: i for i, w in ind2w.items()}
    return ind2w, w2ind


def load_lookups(Y, dataset_dir, version="mimic3", desc_embed=False):
    """
    Inputs:
        args: Input arguments
        desc_embed: true if using DR-CAML
    Outputs:
        vocab lookups, ICD code lookups, description lookup, description one-hot vector lookup
    """
    vocab_file = "%s/vocab.csv" % dataset_dir
    label_file = "%s/label.csv" % dataset_dir
    train_path = "%s/train.csv" % dataset_dir

    # get vocab lookups
    ind2w, w2ind = load_vocab_dict(vocab_file)

    # get code and description lookups
    if Y == "full":
        ind2c, desc_dict = load_full_codes(train_path, version=version)
    else:
        codes = set()
        with open(label_file, "r") as labelfile:
            lr = csv.reader(labelfile)
            for i, row in enumerate(lr):
                codes.add(row[0])
        ind2c = {i: c for i, c in enumerate(sorted(codes))}
        desc_dict = load_code_descriptions(version=version)
    c2ind = {c: i for i, c in ind2c.items()}

    # get description one-hot vector lookup
    if desc_embed:
        dv_dict = load_description_vectors(dataset_dir)
    else:
        dv_dict = None

    dicts = {
        "ind2w": ind2w,
        "w2ind": w2ind,
        "ind2c": ind2c,
        "c2ind": c2ind,
        "desc": desc_dict,
        "dv": dv_dict,
    }
    return dicts


def load_full_codes(train_path, version="mimic3"):
    """
    Inputs:
        train_path: path to train dataset
        version: which (MIMIC) dataset
    Outputs:
        code lookup, description lookup
    """
    # get description lookup
    desc_dict = load_code_descriptions(version=version)
    # build code lookups from appropriate datasets
    if version == "mimic2":
        ind2c = defaultdict(str)
        codes = set()
        with open("%s/proc_dsums.csv" % MIMIC_2_DIR, "r") as f:
            r = csv.reader(f)
            # header
            next(r)
            for row in r:
                codes.update(set(row[-1].split(";")))
        codes = set([c for c in codes if c != ""])
        ind2c = defaultdict(str, {i: c for i, c in enumerate(sorted(codes))})
    else:
        codes = set()
        for split in ["train", "dev", "test"]:
            with open(train_path.replace("train", split), "r") as f:
                lr = csv.reader(f)
                next(lr)
                for row in lr:
                    for code in row[3].split(";"):
                        codes.add(code)
        codes = set([c for c in codes if c != ""])
        ind2c = defaultdict(str, {i: c for i, c in enumerate(sorted(codes))})
    return ind2c, desc_dict


def reformat(code, is_diag):
    """
    Put a period in the right place because the MIMIC-3 data files exclude them.
    Generally, procedure codes have dots after the first two digits,
    while diagnosis codes have dots after the first three digits.
    """
    code = "".join(code.split("."))
    if is_diag:
        if code.startswith("E"):
            if len(code) > 4:
                code = code[:4] + "." + code[4:]
        else:
            if len(code) > 3:
                code = code[:3] + "." + code[3:]
    else:
        code = code[:2] + "." + code[2:]
    return code


def load_code_descriptions(version="mimic3"):
    # load description lookup from the appropriate data files
    desc_dict = defaultdict(str)
    if version == "mimic2":
        with open("%s/MIMIC_ICD9_mapping" % MIMIC_2_DIR, "r") as f:
            r = csv.reader(f)
            # header
            next(r)
            for row in r:
                desc_dict[str(row[1])] = str(row[2])
    else:
        with open("%s/D_ICD_DIAGNOSES.csv" % (MIMIC_3_DIR), "r") as descfile:
            r = csv.reader(descfile)
            # header
            next(r)
            for row in r:
                code = row[1]
                desc = row[-1]
                desc_dict[reformat(code, True)] = desc
        with open("%s/D_ICD_PROCEDURES.csv" % (MIMIC_3_DIR), "r") as descfile:
            r = csv.reader(descfile)
            # header
            next(r)
            for row in r:
                code = row[1]
                desc = row[-1]
                if code not in desc_dict.keys():
                    desc_dict[reformat(code, False)] = desc
        with open("%s/ICD9_descriptions" % DATA_DIR, "r") as labelfile:
            for i, row in enumerate(labelfile):
                row = row.rstrip().split()
                code = row[0]
                if code not in desc_dict.keys():
                    desc_dict[code] = " ".join(row[1:])
    return desc_dict


def load_description_vectors(dataset_dir):
    # load description one-hot vectors from file
    dv_dict = {}
    with open("%s/description_vectors.vocab" % (dataset_dir), "r") as vfile:
        r = csv.reader(vfile, delimiter=" ")
        # header
        next(r)
        for row in r:
            code = row[0]
            vec = [int(x) for x in row[1:]]
            dv_dict[code] = vec
    return dv_dict


# From dataproc/extract_wvs.py
def load_embeddings(embed_file):
    # also normalizes the embeddings
    W = []
    with open(embed_file) as ef:
        for line in ef:
            line = line.rstrip().split()
            vec = np.array(line[1:]).astype(np.float)
            vec = vec / float(np.linalg.norm(vec) + 1e-6)
            W.append(vec)
        # UNK embedding, gaussian randomly initialized
        print("adding unk embedding")
        vec = np.random.randn(len(W[-1]))
        vec = vec / float(np.linalg.norm(vec) + 1e-6)
        W.append(vec)
    W = np.array(W)
    return W
