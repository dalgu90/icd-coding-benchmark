paths:
  mimic_dir: &mimic_dir datasets/mimic3/csv
  static_dir: &static_dir datasets/mimic3/static
  dataset_dir: &dataset_dir datasets/mimic3_50
  word2vec_dir: &word2vec_dir datasets/mimic3_50/word2vec

preprocessing:
  name: mimic_iii_preprocessing_pipeline
  params:
    paths:
      mimic_dir: *mimic_dir
      static_dir: *static_dir
      save_dir: *dataset_dir
      diagnosis_code_csv_name: DIAGNOSES_ICD.csv.gz
      procedure_code_csv_name: PROCEDURES_ICD.csv.gz
      noteevents_csv_name: NOTEEVENTS.csv.gz
      train_json_name: train.json       # will be saved
      val_json_name: val.json           # will be saved
      test_json_name: test.json         # will be saved
      label_json_name: labels.json      # will be computed and saved
      label_freq_json_name: null
    dataset_metadata:
      column_names:
        subject_id: SUBJECT_ID
        hadm_id: HADM_ID
        chartdate: CHARTDATE
        charttime: CHARTTIME
        storetime: STORETIME
        category: CATEGORY
        description: DESCRIPTION
        cgid: CGID
        iserror: ISERROR
        text: TEXT
        icd9_code: ICD9_CODE
        labels: LABELS
    dataset_splitting_method:
      name: caml_official_split
      params:
        hadm_dir: *static_dir
        train_hadm_ids_name: train_full_split.json
        val_hadm_ids_name: val_full_split.json
        test_hadm_ids_name: test_full_split.json
    clinical_note_preprocessing:
      to_lower:
        perform: true
      remove_punctuation:
        perform: true
      remove_numeric:
        perform: true
        replace_numerics_with_letter: null
      remove_stopwords:
        perform: true
        params:
          stopwords_file_path: null
          remove_common_medical_terms: true
      stem_or_lemmatize:
        perform: true
        params:
          stemmer_name: nltk.WordNetLemmatizer
      truncate:
        perform: false
    incorrect_code_loading: false
    count_duplicates: false
    code_preprocessing:
      top_k: 50                       # enter 0 for all codes
      code_type: both
      add_period_in_correct_pos:
        perform: true
    train_embed_with_all_split: false
    tokenizer:
      name: spacetokenizer
      params: null
    embedding:
      name: word2vec
      params:
        embedding_dir: *word2vec_dir
        pad_token: "<pad>"
        unk_token: "<unk>"
        word2vec_params:
          vector_size: 100
          min_count: 3
          epochs: 5
