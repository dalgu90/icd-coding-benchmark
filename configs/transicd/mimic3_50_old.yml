paths:
  mimic_dir: &mimic_dir datasets/mimic3/csv
  static_dir: &static_dir datasets/mimic3/static
  dataset_dir: &dataset_dir datasets/mimic3_50_old
  word2vec_dir: &word2vec_dir datasets/mimic3_50_old/word2vec
  output_dir: &output_dir results/transicd_mimic3_50_old

dataset:
  name: base_dataset
  data_common: &data_common
    column_names:
      hadm_id: "HADM_ID"
      clinical_note: "TEXT"
      labels: "LABELS"
    word2vec_dir: *word2vec_dir
    pad_token: "<pad>"
    unk_token: "<unk>"
    dataset_dir: *dataset_dir
    label_file: labels.json
    max_length: 2500
  params:
    train:
      <<: *data_common
      data_file: train.json
    val:
      <<: *data_common
      data_file: val.json
    test:
      <<: *data_common
      data_file: test.json

model:
  name: transicd
  params:
    num_classes: 50
    max_len: 2500
    pad_idx: 0
    # Embedding Layer params
    embed_dir: *word2vec_dir
    freeze_embedding_layer: true
    # Transformer Layer params
    num_layers: 2
    num_heads: 8
    transformer_ff_up_scale_factor_for_hidden_dim: 4
    dropout: 0.2
    # Label Attention Layer params
    attn_expansion: 2
    epsilon: !!float 1e-9
    use_gpu: true

trainer:
  name: base_trainer
  params:
    output_dir: *output_dir
    data_loader:
      batch_size: 8
      num_workers: 4
      shuffle: false
      drop_last: true
    loss:
      name: BinaryCrossEntropyLoss
      params: null
    optimizer:
      name: adam_w
      params:
        lr: 0.001
        weight_decay: 0.01
    max_epochs: 30
    lr_scheduler: null
    stopping_criterion:
      metric:
        name: prec_at_8
      desired: max
      patience: 10
    checkpoint_saver:
      name: base_saver
      params:
        checkpoint_dir: *output_dir
        interval: 1
        max_to_keep: 5
        ckpt_fname_format: "ckpt-{}.pth"
        best_fname_format: "best-{}.pth"
        metric:
          name: prec_at_8
          class: prec_at_k
          params:
            k: 8
        desired: max
    eval_metrics: &eval_metrics
      - name: prec_at_5
        class: prec_at_k
        params:
          k: 5
      - name: prec_at_8
        class: prec_at_k
        params:
          k: 8
      - name: macro_f1
      - name: micro_f1
      - name: macro_auc
      - name: micro_auc
    graph:
      writer:
        name: tensorboard
        params:
          log_dir: *output_dir
      train:
        interval: 100
        interval_unit: step
        metric:
          - name: loss
      val:
        interval: 1
        interval_unit: epoch
        metric:
          - name: loss
          - name: prec_at_5
          - name: prec_at_8
          - name: macro_f1
          - name: micro_f1
          - name: macro_auc
          - name: micro_auc
    seed: 1
    use_gpu: true
